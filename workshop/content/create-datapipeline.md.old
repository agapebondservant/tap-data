
### Create Data Pipeline

Using the previously created data resources, we will set up a data pipeline using **VMware Spring Cloud Data Flow**. Let's set up a new data pipeline:

<font color=red>DONT RUN THIS!!!</font>

```execute
clear && export DATA_E2E_WAVEFRONT_ACCESS_TOKEN={{ DATA_E2E_WAVEFRONT_ACCESS_TOKEN }} && export DATA_E2E_WAVEFRONT_SOURCE={{ DATA_E2E_WAVEFRONT_SOURCE  }} && export DATA_E2E_GRAFANA_URL={{ DATA_E2E_GRAFANA_URL }} && kubectl create secret docker-registry scdf-image-regcred --namespace={{ session_namespace }} --docker-server=registry.pivotal.io --docker-username='{{ DATA_E2E_PIVOTAL_REGISTRY_USERNAME }}' --docker-password='{{ DATA_E2E_PIVOTAL_REGISTRY_PASSWORD }}' --dry-run -o yaml | kubectl apply -f - && chmod +x ~/other/resources/scdf/configure.sh  && source ~/other/resources/scdf/configure.sh && kubectl create secret generic wavefront-api --from-literal=wavefront-api-token={{ DATA_E2E_WAVEFRONT_ACCESS_TOKEN }} --dry-run -o yaml | kubectl apply -f - && kubectl kustomize ~/other/resources/scdf/apps/skipper/kustomize/overlays/production/ | kapp deploy -y -a skipper -f - && kubectl kustomize ~/other/resources/scdf/apps/data-flow/kustomize/overlays/production/ | kapp deploy -y -a data-flow -f -
```
<font color=red>RUN THIS!!!</font>
```execute
clear && export DATA_E2E_WAVEFRONT_ACCESS_TOKEN={{ DATA_E2E_WAVEFRONT_ACCESS_TOKEN }} && export DATA_E2E_WAVEFRONT_SOURCE={{ DATA_E2E_WAVEFRONT_SOURCE  }} && export DATA_E2E_GRAFANA_URL={{ DATA_E2E_GRAFANA_URL }} && kubectl create secret docker-registry scdf-image-regcred --namespace={{ session_namespace }} --docker-server=registry.pivotal.io --docker-username='{{ DATA_E2E_PIVOTAL_REGISTRY_USERNAME }}' --docker-password='{{ DATA_E2E_PIVOTAL_REGISTRY_PASSWORD }}' --dry-run -o yaml | kubectl apply -f - && chmod +x ~/other/resources/scdf/configure.sh  && source ~/other/resources/scdf/configure.sh && kubectl create secret generic wavefront-api --from-literal=wavefront-api-token={{ DATA_E2E_WAVEFRONT_ACCESS_TOKEN }} --dry-run -o yaml | kubectl apply -f - && ~/other/resources/scdf/bin/install-dev.sh
```

Let's view the Spring Cloud Data Flow dashboard:
```dashboard:create-dashboard
name: Example
url: {{ ingress_protocol }}://scdf-{{ session_namespace }}.{{ DATA_E2E_BASE_URL }}
```

Greenplum;
Now, generate a **logistic regression** model from the data via **MADLib**:
```execute
SELECT madlib.logregr_train('madlib.pxf_clinical_data_000', 'madlib.clinical_data_logreg','recommended','ARRAY[1, treatment_cost, wait_time]');

SELECT unnest(array['intercept', 'treatment_cost', 'wait_time']) as attribute,
       unnest(coef) as coefficient,
       unnest(std_err) as standard_error,
       unnest(z_stats) as z_stat,
       unnest(p_values) as pvalue,
       unnest(odds_ratios) as odds_ratio
    FROM madlib.clinical_data_logreg;
```